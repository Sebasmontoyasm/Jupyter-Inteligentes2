{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción al aprendizaje de máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El aprendizaje de máquina se fundamenta en el reconocimiento de patrones y la minería de datos. A su vez, estos nacen a partir de la ciencia de datos, que comprende herramientas provenientes de la estadística, el cálculo, el álgebra lineal y otras ciencias puras. \n",
    "\n",
    "Las máquinas, igual que los seres humanos, aprenden a partir de ejemplos. El proceso de aprendizaje se denomina \"entrenamiento\" y requiere entonces de un conjunto de datos de entrenamiento que la máquina pueda usar para aprender. El aprendizaje consiste en encontrar patrones que puedan ser extrapolables a otros casos que no necesariamente hayan estado en la etapa de entrenamiento.  \n",
    "\n",
    "¿Cómo diferenciar limones, naranjas y manzanas?\n",
    "https://homepages.inf.ed.ac.uk/imurray2/teaching/oranges_and_lemons/\n",
    "\n",
    "Los datos pueden descargarse de aquí:\n",
    "https://homepages.inf.ed.ac.uk/imurray2/teaching/oranges_and_lemons/fruit_data\n",
    "\n",
    "Y la descripción de a qué corresponde cada muestra está aquí:\n",
    "https://homepages.inf.ed.ac.uk/imurray2/teaching/oranges_and_lemons/fruit_types.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "dataset = np.genfromtxt('/home/sebas/Escritorio/inteligentes2/databases/lnm.txt') \n",
    "muestras = dataset[:,1:3] #Tomamos dos características\n",
    "clase = dataset[:,0]\n",
    "plt.scatter(muestras[:,0],muestras[:,1],c=clase)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paquete SciKit Learn contiene una cantidad de conjuntos de datos y herramientas útiles para el aprendizaje de máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "# Importamos la base de datos iris\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:,0:2]  # Tomamos las dos primeras características (150 muestras, 2 características)\n",
    "y = iris.target #Etiquetas\n",
    "plt.scatter(X[:, 0], X[:, 1],c=y)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.show()\n",
    "print(X) #Éste es el vector de etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "¿Cómo encontrar una frontera que separe correctamente los datos?\n",
    "Consideremos solamente dos clases: Setosa y versicolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[0:100, 0:2]  # Tomamos las dos primeras características, las primeras 100 muestras\n",
    "y = iris.target[0:100] #Tomamos las primeras 100 etiquetas\n",
    "plt.scatter(X[:, 0], X[:, 1],c=y)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un clasificador discriminativo se enfoca en encontrar una frontera de decisión que separe correctamente los datos. Una linea recta en dos dimensiones está dada por:\n",
    "\n",
    "\\begin{equation}\n",
    "w_1 x_1 + w_2 x_2 + w_0 = 0\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "x_2 = -\\frac{w_1}{w_2}x_1 - \\frac{w_0}{w_2} \n",
    "\\end{equation}\n",
    "\n",
    "O en notación vectorial:\n",
    "\n",
    "\\begin{equation}\n",
    "[w_1 w_2 w_0] \\left[\n",
    "\\begin{array}{c}\n",
    "x_1\\\\\n",
    "x_2\\\\\n",
    "1\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\boldsymbol{w}^T \\boldsymbol{x} = 0\n",
    "\\end{equation}\n",
    "\n",
    "Esta ecuación se llama \"función discriminante lineal\". $\\boldsymbol{w}$ representa un vector normal a la frontera de decisión y $\\boldsymbol{x}$ es cada una de las muestras en la base de datos. El conjunto total lo denominaremos $\\boldsymbol{X}$ y es una matriz donde cada fila es una muestra y cada columna es una característica.\n",
    "\n",
    "Lo más importante de la función discriminante lineal es que nos permite realizar predicciones. Recordemos un poco de álgebra lineal:\n",
    "\n",
    "\\begin{equation}\n",
    "\\boldsymbol{w}^T \\boldsymbol{x} = \\|\\boldsymbol{x}\\| \\|\\boldsymbol{w}\\| \\cos(\\theta)\n",
    "\\end{equation}\n",
    "\n",
    "<div>\n",
    "<img src=\"feature_space.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "Podemos ver que para todas las muestras que estén sobre la frontera de decisión, el ángulo $\\theta$ será menor a 90°, mientras que para las que estén por debajo de la frontera, estará entre 90° y 180°. Ahora analicemos la función coseno:\n",
    "\n",
    "<div>\n",
    "<img src=\"cosine.png\" width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "¡Las muestras que estén sobre la frontera de decisión tendrán valores positivos y las que estén por debajo tendrán valores negativos!\n",
    "\n",
    "¿Qué significa encontrar una frontera que separe \"correctamente\" los datos? Definamos una medida de el error que comete la función discriminante lineal usando mínimos cuadrados:\n",
    "\n",
    "\\begin{equation}\n",
    "\\varepsilon = \\frac{1}{2}\\sum_{i=1}^n (\\boldsymbol{w}^T \\boldsymbol{x}_i - y_i)^2\n",
    "\\end{equation}\n",
    "\n",
    "Si queremos minimizar el error, derivamos y despejamos $\\boldsymbol{w}$. Esto nos lleva a:\n",
    "\n",
    "\\begin{equation}\n",
    "\\boldsymbol{w} = \\left( \\boldsymbol{X}^T \\boldsymbol{X}\\right)^{-1}\\boldsymbol{X}^T\\boldsymbol{y}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.where(y==-1,2,y) #Reemplazamos los 0's por -1's \n",
    "Xm=np.hstack((X,np.ones((100,1)))) #Agregamos unos en la última columna de X\n",
    "XTX = np.transpose(Xm).dot(Xm)\n",
    "XTXi = np.linalg.inv(XTX)\n",
    "wm=((XTXi).dot(np.transpose(Xm))).dot(y)\n",
    "print(wm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí finaliza el entrenamiento. La máquina ha aprendido cómo diferenciar entre una iris del tipo setosa y una iris del tipo virginica. ¿Cómo se usa este conocimiento adquirido?\n",
    "\n",
    "\\begin{equation}\n",
    "\\boldsymbol{w}\\boldsymbol{x}^T = \\left\\{ \\begin{array}{l}\n",
    ">0, virginica\\\\\n",
    "<0, setosa\n",
    "\\end{array}\\right.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=np.array([[5.3, 3.5, 1]])\n",
    "prediccion=np.sign(wm.dot(np.transpose(test)))\n",
    "print(prediccion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Y cómo se hace en sklearn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.RidgeClassifier(alpha=0).fit(X[0:100,:2], y[0:100]) #Entrenamiento\n",
    "test=np.array([[5.3,3.5]]) #Prueba\n",
    "clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
